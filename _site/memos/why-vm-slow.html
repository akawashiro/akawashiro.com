<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><!-- Begin Jekyll SEO tag v2.8.0 -->
<title>VM の実装とその性能 | Akira Kawata</title>
<meta name="generator" content="Jekyll v4.3.4" />
<meta property="og:title" content="VM の実装とその性能" />
<meta property="og:locale" content="en_US" />
<link rel="canonical" href="/memos/why-vm-slow.html" />
<meta property="og:url" content="/memos/why-vm-slow.html" />
<meta property="og:site_name" content="Akira Kawata" />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="VM の実装とその性能" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"WebPage","headline":"VM の実装とその性能","url":"/memos/why-vm-slow.html"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/assets/main.css"><link type="application/atom+xml" rel="alternate" href="/feed.xml" title="Akira Kawata" /></head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/">Akira Kawata</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>
      </nav></div>
</header>

<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <h1 id="vm-の実装とその性能">VM の実装とその性能</h1>

<h2 id="regcpython-a-register-based-python-interpreter-for-better-performance"><a href="https://dl.acm.org/doi/pdf/10.1145/3568973">RegCPython: A Register-based Python Interpreter for Better Performance</a></h2>
<h3 id="citation">Citation</h3>
<p>Qiang Zhang, Lei Xu, and Baowen Xu. 2022. RegCPython: A Register-based Python Interpreter for Better Performance. ACM Trans. Archit. Code Optim. 20, 1, Article 14 (March 2023), 25 pages. https://doi.org/10.1145/3568973</p>
<h3 id="abstract">Abstract</h3>
<p>Interpreters are widely used in the implementation of many programming languages, such as Python, Perl, and Java. Even though various JIT compilers emerge in an endless stream, interpretation efficiency still plays a critical role in program performance. Does a stack-based interpreter or a register-based interpreter perform better? The pros and cons of the pair of architectures have long been discussed. The stack architecture is attractive for its concise model and compact bytecode, but our study finds that the register-based interpreter can also be implemented easily and that its bytecode size only grows by a small margin. Moreover, the latter turns out to be appreciably faster. Specifically, we implemented an open source Python interpreter named RegCPython based on CPython v3.10.1. The former is register based, while the latter is stack based. Without changes in syntax, Application Programming Interface, and Application Binary Interface, RegCPython is excellently compatible with CPython, as it does not break existing syntax or interfaces. It achieves a speedup of 1.287 on the most favorable benchmark and 0.977 even on the most unfavorable benchmark. For all Python-intensive benchmarks, the average speedup reaches 1.120 on x86 and 1.130 on ARM. Our evaluation work, which also serves as an empirical study, provides a detailed performance survey of both interpreters on modern hardware. It points out that the register-based interpreters are more efficient mainly due to the elimination of machine instructions needed, while changes in branch mispredictions and cache misses have a limited impact on performance. Additionally, it confirms that the register-based implementation is also satisfactory in terms of memory footprint, compilation cost, and implementation complexity.</p>

<h2 id="quantifying-the-interpretation-overhead-of-python">Quantifying the interpretation overhead of Python</h2>
<h3 id="citation-1">Citation</h3>
<p>Qiang Zhang, Lei Xu, Xiangyu Zhang, and Baowen Xu. 2022. Quantifying the interpretation overhead of Python. Sci. Comput. Program. 215, C (Mar 2022). https://doi.org/10.1016/j.scico.2021.102759</p>
<h3 id="abstract-1">Abstract</h3>
<p>While Python has become increasingly popular for its convenience, it is also criticized for its suboptimal performance. To figure out what burdens the interpreter of Python and provide insights into possible optimizations, we conduct this empirical study on CPython’s performance via sampling-based profiling. This sampling-based approach incurs a low runtime overhead and does not require any modification of the interpreter and the application code, thus providing convincing experimental results. Specifically, we use 48 benchmarks from the pyperformance project to analyze the runtime overhead of the interpreter. We compare the usage of different opcodes and decompose the overhead at various granularities (e.g., files, functions, and statements). It turns out that most parts contribute a small portion of the overhead, and the promising improvements lie in the minority, such as name access opcodes and reference counting functions. Furthermore, we pay attention to four specific performance-affecting issues: name access, dynamic typing, garbage collection, and opcode dispatch. The issue study reveals several promising optimization techniques, such as register-based virtual machine architecture and tracing-based garbage collection, as well as a few fruitless optimization points, such as operator overloading and dispatch.</p>

<h2 id="virtual-machine-showdown-stack-versus-registers"><a href="https://dl.acm.org/doi/pdf/10.1145/1328195.1328197">Virtual machine showdown: Stack versus registers</a></h2>
<h3 id="citation-2">Citation</h3>
<p>Yunhe Shi, Kevin Casey, M. Anton Ertl, and David Gregg. 2008. Virtual machine showdown: Stack versus registers. ACM Trans. Archit. Code Optim. 4, 4, Article 2 (January 2008), 36 pages. https://doi.org/10.1145/1328195.1328197</p>
<h3 id="abstract-2">Abstract</h3>
<p>Virtual machines (VMs) enable the distribution of programs in an architecture-neutral format, which can easily be interpreted or compiled. A long-running question in the design of VMs is whether a stack architecture or register architecture can be implemented more efficiently with an interpreter. We extend existing work on comparing virtual stack and virtual register architectures in three ways. First, our translation from stack to register code and optimization are much more sophisticated. The result is that we eliminate an average of more than 46% of executed VM instructions, with the bytecode size of the register machine being only 26% larger than that of the corresponding stack one. Second, we present a fully functional virtual-register implementation of the Java virtual machine (JVM), which supports Intel, AMD64, PowerPC and Alpha processors. This register VM supports inline-threaded, direct-threaded, token-threaded, and switch dispatch. Third, we present experimental results on a range of additional optimizations such as register allocation and elimination of redundant heap loads. On the AMD64 architecture the register machine using switch dispatch achieves an average speedup of 1.48 over the corresponding stack machine. Even using the more efficient inline-threaded dispatch, the register VM achieves a speedup of 1.15 over the equivalent stack-based VM.</p>

<h2 id="the-case-for-virtual-register-machines"><a href="https://dl.acm.org/doi/10.1016/j.scico.2004.08.005">The case for virtual register machines</a></h2>
<h3 id="citation-3">Citation</h3>
<p>David Gregg, Andrew Beatty, Kevin Casey, Brain Davis, and Andy Nisbet. 2005. The case for virtual register machines. Sci. Comput. Program. 57, 3 (September 2005), 319–338. https://doi.org/10.1016/j.scico.2004.08.005</p>
<h3 id="abstract-3">Abstract</h3>
<p>Virtual machines (VMs) are a popular target for language implementers. A long-running question in the design of virtual machines has been whether stack or register architectures can be implemented more efficiently with an interpreter. Many designers favour stack architectures since the location of operands is implicit in the stack pointer. In contrast, the operands of register machine instructions must be specified explicitly. In this paper, we present a working system for translating stack-based Java virtual machine (JVM) code to a simple register code. We describe the translation process, the complicated parts of the JVM which make translation more difficult, and the optimisations needed to eliminate copy instructions. Experimental results show that a register format reduced the number of executed instructions by 34.88%, while increasing the number of bytecode loads by an average of 44.81%. Overall, this corresponds to an increase of 2.32 loads for each dispatch removed. We believe that the high cost of dispatches makes register machines attractive even at the cost of increased loads.</p>

<h2 id="the-structure-and-performance-of-efficient-interpreters"><a href="https://jilp.org/vol5/v5paper12.pdf">The Structure and Performance of Efficient Interpreters</a></h2>
<h3 id="memo">Memo</h3>
<p>https://news.ycombinator.com/item?id=13990592</p>
<h3 id="citation-4">Citation</h3>
<p>Ertl, M. Anton, and David Gregg. “The structure and performance of efficient interpreters.” Journal of Instruction-Level Parallelism 5 (2003): 1-25.</p>
<h3 id="abstract-4">Abstract</h3>
<p>Interpreters designed for high general-purpose performance typically perform a large
number of indirect branches (3.2%–13% of all executed instructions in our benchmarks). These branches consume more than half of the run-time in a number of configurations we simulated. We evaluate how accurate various existing and proposed branch prediction schemes are on a number of interpreters, how the mispredictions affect the performance of the interpreters and how two different interpreter implementation techniques perform with various branch predictors. We also suggest various ways in which hardware designers, C compiler writers, and interpreter writers can improve the performance of interpreters</p>

<h2 id="the-structure-and-performance-of-interpreters"><a href="https://dl.acm.org/doi/pdf/10.1145/237090.237175">The Structure and Performance of Interpreters</a></h2>
<h3 id="citation-5">Citation</h3>
<p>Theodore H. Romer, Dennis Lee, Geoffrey M. Voelker, Alec Wolman, Wayne A. Wong, Jean-Loup Baer, Brian N. Bershad, and Henry M. Levy. 1996. The structure and performance of interpreters. In Proceedings of the seventh international conference on Architectural support for programming languages and operating systems (ASPLOS VII). Association for Computing Machinery, New York, NY, USA, 150–159. https://doi.org/10.1145/237090.237175</p>
<h3 id="abstract-5">Abstract</h3>
<p>Interpreted languages have become increasingly popular due to demands for rapid program development, ease of use, portability, and safety. Beyond the general impression that they are “slow,” however, little has been documented about the performance of interpreters as a class of applications.This paper examines interpreter performance by measuring and analyzing interpreters from both software and hardware perspectives. As examples, we measure the MIPSI, Java, Perl, and Tcl interpreters running an array of micro and macro benchmarks on a DEC Alpha platform. Our measurements of these interpreters relate performance to the complexity of the interpreter’s virtual machine and demonstrate that native runtime libraries can play a key role in providing good performance. From an architectural perspective, we show that interpreter performance is primarily a function of the interpreter itself and is relatively independent of the application being interpreted. We also demonstrate that high-level interpreters’ demands on processor resources are comparable to those of other complex compiled programs, such as gcc. We conclude that interpreters, as a class of applications, do not currently motivate special hardware support for increased performance.</p>

      </div>
    </main><footer class="site-footer h-card">
</footer>
</body>

</html>
